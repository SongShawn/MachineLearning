## 1 定义

### 1.1 项目概述
项目是Kaggle上的一个竞赛，该竞赛的目的是利用机器学习方法预测旧金山可能发生的犯罪类型。

1849年，随着加州淘金热的浪潮，旧金山经历了第一次繁荣，在随后的的几十年经历了城市面积激增和人口爆炸。人口的爆炸不可避免的带来了社会问题和高犯罪率，当然红灯区的存在也是一个很重要的原因[^1]。1934至1963年，旧金山因将一些罪行严重的罪犯关在恶魔岛而声名狼藉。而今因为很多高科技公司的存在，科技标签已经远远超过了其它标签的影响力。但是因为财富不均等、房屋短缺等因素，这里并不缺少犯罪[^2]。所以实现犯罪类型的预测对预防犯罪和降低犯罪带来的损失都能起到很大的作用。

[^1]: Yehya Abouelnaga, "San Francisco Crime Classification", The American University in Cairo, 2016
[^2]: San Francisco Crime Classification in Kaggle, https://www.kaggle.com/c/sf-crime

项目属于监督学习中的多标签分类问题。线性回归、KNN、朴素贝叶斯、决策树和随机森林机器学习算法对于特定的问题都能够实现非常不错的分类效果。

有人的地方就有可能有犯罪，因此通过机器学习帮助我们加深对犯罪发生模式的理解是对社会建设很有意义的一件事。更关键的是，对犯罪类型和犯罪率的预测能够帮助警察局更加有效的分配警力和打击犯罪率激增。

### 1.2 问题陈述

项目实质上就是一个监督学习的多分类问题，分类种类多达39种。训练集提供了9个特征，其中特征'Category'属于样本的标签。

项目需要使用机器学习算法通过训练集进行训练，最终得到一个可以根据特征预测犯罪类型的模型。

我将使用随机森林和XGBoost中的提升树两种机器学习算法对数据进行一个基本的学习，然后选择一个效果最好的模型进行优化。


### 1.3 评价指标

使用多分类对数损失作为评估指标，公式如下：[^3]
$$ logloss = -\frac{1}{M}\sum_{i=1}^M{\sum_{j=1}^N{y_{ij}\log{p_{ij}}}} $$

- M: 数据集样本个数。
- N: 分类问题类别个数。
- $y_{ij}$: $j_{th}类别为$$i_{th}$真实类别时，$y_{ij}$为1，其余情况均为0。
- $p_{ij}$: 分类器预测$i_{th}$样本为$j_{th}$类别的概率。

损失函数y = -log(x)的函数图像如下：
<img src="images/-log(x).jpg" width = "600" height = "400" alt="犯罪类型热点图" align=center />
从对数损失公式可以看出，只有分配给真实标签的概率会对损失值造成影响，假设模型预测错误，分配给真实标签的概率将会是一个比较小的数值，从函数图像中可以发现，概率越小得到的惩罚越大且增长迅速。反过来，模型预测正确，真实标签将得到一个比较大的数值，对于该样本则会返回一个非常小的损失值。

最大最小规则[^4]：
对于对数损失公式，$p_{ij}$为0或1时是没有意义的，因此通过引入一个极小值($\epsilon$)来杜绝这种情况的发生。公式如下：
```python
max(min(p, 1 - epsilon), epsilon)
```
根据题目要求，我们设置$\epsilon$为$10^{-15}$。

[^3]: sf-crime#evaluation， https://www.kaggle.com/c/sf-crime#evaluation
[^4]: MinMaxRule, http://wiki.fast.ai/index.php/Log_Loss

## 2 分析

### 2.1 数据可视化
### 2.2 算法与技术
### 2.3 基准模型

## 3 方法