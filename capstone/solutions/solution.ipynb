{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'preprocess' from '/Users/Shawn/github/MachineLearning/capstone/solutions/preprocess.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import visual as vs\n",
    "import numpy as np\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocess as datapre\n",
    "\n",
    "importlib.reload(vs)\n",
    "importlib.reload(datapre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据探索\n",
    "来自于Kaggle名为旧金山罪案类型分类的数据集，该数据集分为训练集和测试集，训练集包含878049个带标签样本，测试集包含884262个未带标签样本。  \n",
    "运行下边代码加载训练集和测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../datasets/train.csv', parse_dates=['Dates'])\n",
    "test_data = pd.read_csv('../datasets/test.csv', parse_dates=['Dates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示训练集部分样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Category</th>\n",
       "      <th>Descript</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>WARRANTS</td>\n",
       "      <td>WARRANT ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-13 23:53:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>OAK ST / LAGUNA ST</td>\n",
       "      <td>-122.425892</td>\n",
       "      <td>37.774599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-13 23:33:00</td>\n",
       "      <td>OTHER OFFENSES</td>\n",
       "      <td>TRAFFIC VIOLATION ARREST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>ARREST, BOOKED</td>\n",
       "      <td>VANNESS AV / GREENWICH ST</td>\n",
       "      <td>-122.424363</td>\n",
       "      <td>37.800414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-13 23:30:00</td>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>GRAND THEFT FROM LOCKED AUTO</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>1500 Block of LOMBARD ST</td>\n",
       "      <td>-122.426995</td>\n",
       "      <td>37.800873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dates        Category                      Descript  \\\n",
       "0 2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n",
       "1 2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "2 2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n",
       "3 2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n",
       "\n",
       "   DayOfWeek PdDistrict      Resolution                    Address  \\\n",
       "0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n",
       "2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n",
       "3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.425892  37.774599  \n",
       "1 -122.425892  37.774599  \n",
       "2 -122.424363  37.800414  \n",
       "3 -122.426995  37.800873  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示测试集部分样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id               Dates DayOfWeek PdDistrict                  Address  \\\n",
       "0   0 2015-05-10 23:59:00    Sunday    BAYVIEW  2000 Block of THOMAS AV   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.399588  37.735051  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除训练集中无用字段\n",
    "训练集中的'Descript'，'Resolution'两个属性无意义，直接删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除无用字段 'Descript' 'Resolution'\n",
    "train_data = train_data.drop(columns=['Descript', 'Resolution'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据集中的缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dates         False\n",
       "Category      False\n",
       "DayOfWeek     False\n",
       "PdDistrict    False\n",
       "Address       False\n",
       "X             False\n",
       "Y             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dates         False\n",
       "Category      False\n",
       "DayOfWeek     False\n",
       "PdDistrict    False\n",
       "Address       False\n",
       "X             False\n",
       "Y             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().any(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**确定训练集中没有缺失数据。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates解析为年月日时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datapre.extra_dates(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DayOfWeek转化为数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "DayOfWeekEnc = LabelEncoder()\n",
    "train_data['DayOfWeekID'] = DayOfWeekEnc.fit_transform(train_data['DayOfWeek'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PdDistrict转化为数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PdDistrictEnc = LabelEncoder()\n",
    "train_data['PdDistrictID'] = PdDistrictEnc.fit_transform(train_data['PdDistrict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从Address中提取是否含有Block字段作为特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datapre.extra_address_for_block(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从Address中提取地址后缀作为特征\n",
    "- 标准的地址都会含有一个简写后缀表示道路的类型，直接解析后缀，如：\"200 Block of INTERSTATE80 HY\"解析为\"HY\"。\n",
    "- 对于路口则会表示成'XX ST / YY ST'，直接解析为\"CrossRoad\"，如：\"STCHARLES AV / 19TH AV\"解析为\"CrossRoad\"。\n",
    "- 对于直接含有道路类型全名的地址也要进行解析。如：\"0 Block of AVENUE OF THE PALMS\"中的\"AVENUE\"就是道路类型。\n",
    "- 对于上述三种方式都无法解析，则直接设置为\"Unkown\"。  \n",
    "\n",
    "根据直觉判断，不同类型的道路发生各种类型犯罪的分布是不一样的。如：铁路附近发生自杀案件的概率普遍高于其他案件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['PositionType'] = None\n",
    "suffixs = [\"AL\",\"AV\",\"BL\",\"CR\",\"CT\",\"DR\",\"EX\",\"HWY\",\"HY\",\"LN\",\"PL\",\"PZ\",\"RD\",\"ST\",\"TR\",\"WY\",\"WAY\"]\n",
    "suffix_names = [\"Alley\",\"Avenue\",\"Boulevard\",\"Circle\",\"Court\",\"Drive\",\"Expressway\",\"Highway\",\"Highway\",\n",
    "                \"Lane\",\"Place\",\"Plaza\",\"Road\",\"Street\",\"Terrace\",\"Way\",\"Way\"]\n",
    "cross_road = \"CrossRoad\" # 交叉路口，含有/的\n",
    "unkown_road = \"Unkown\"\n",
    "\n",
    "# 设置交叉路口\n",
    "train_data.loc[train_data['Address'].str.contains('/'), 'PositionType'] = cross_road\n",
    "\n",
    "# 查找缩写并设置\n",
    "for a in suffixs:\n",
    "    train_data.loc[(train_data['Address'].str.contains('/') == False) \n",
    "                   & (train_data['Address'].str.contains(' '+a+'$')), 'PositionType'] = a\n",
    "    \n",
    "# 查找全程并设置\n",
    "for i,d in enumerate(suffix_names):\n",
    "    train_data.loc[(train_data['PositionType'].isna())\n",
    "                   & (train_data['Address'].str.contains(d, case=False)), 'PositionType'] = suffixs[i]\n",
    "    \n",
    "# 无法解析的均设置为Unkown\n",
    "train_data.loc[(train_data['PositionType'].isna()), 'PositionType'] = unkown_road\n",
    "\n",
    "# 合并 HWY HY，合并 WY WAY\n",
    "train_data.loc[train_data['PositionType'] == \"HWY\", \"PositionType\"] = \"HY\"\n",
    "train_data.loc[train_data['PositionType'] == \"WAY\", \"PositionType\"] = \"WY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PositionType转化为数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PositionTypeEnc = LabelEncoder()\n",
    "train_data['PositionTypeID'] = PositionTypeEnc.fit_transform(train_data['PositionType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dates', 'Category', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y',\n",
       "       'Year', 'Month', 'Day', 'Hour', 'DayOfWeekID', 'PdDistrictID',\n",
       "       'HasBlock', 'PositionType', 'PositionTypeID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存预处理后的训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"../datasets/train_preprocess.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 删除含有异常值的样本\n",
    "属性'Category'、'PdDistrict'为类别，存在既有意义。属性'Address'为自由字符串，存在既有意义。\n",
    "- Dates，需要在特定区间内\n",
    "- DayOfWeek，只能有七种类型\n",
    "- X，Y，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bound = [-122.52, -122.35]\n",
    "Y_bound = [37.70, 37.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(878049, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877982, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[(train_data['X'] > X_bound[0]) & (train_data['X'] < X_bound[1]) \n",
    "               & (train_data['Y'] > Y_bound[0]) & (train_data['Y'] < Y_bound[1])].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 设置训练模型特征名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Year', 'Month', 'Day', 'Hour', 'DayOfWeekID', 'PdDistrictID', 'HasBlock', 'PositionTypeID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用KNN算法进行分类\n",
    "使用KNN算法以X、Y经纬度作为特征对训练集进行分类，将分类结果作为新的特征并入到训练集中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用XGBoost作为预测算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出训练集中的预测目标字段\n",
    "\n",
    "sample_data = train_data.sample(frac = 0.3, random_state=10)\n",
    "\n",
    "target = sample_data['Category']\n",
    "features = sample_data[feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEncTarget = LabelEncoder()\n",
    "target = LabelEncTarget.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "print('X_train has {} samples.'.format(X_train.shape[0]))\n",
    "print('X_test has {} samples.'.format(X_test.shape[0]))\n",
    "\n",
    "DTrain_X = xgb.DMatrix(data=X_train, label=y_train)\n",
    "DTest_X = xgb.DMatrix(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def products(data):\n",
    "    results = [[]]\n",
    "    for a in data:\n",
    "        results = [x+[y] for x in results for y in a]\n",
    "    for a in results:\n",
    "        yield tuple(a)\n",
    "        \n",
    "def extra_params(param, param_grid):\n",
    "    param_names = list(param_grid)\n",
    "    params = []\n",
    "    filenames = []\n",
    "    param_sets = products(param_grid.values())\n",
    "    for a in param_sets:\n",
    "        b = param.copy()\n",
    "        for key,value in zip(param_names, a):\n",
    "            b[key] = value\n",
    "        params.append(b)\n",
    "        filenames.append('_'.join([str(i) for i in a]))\n",
    "    return params,filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from os import makedirs, system\n",
    "\n",
    "param = {}\n",
    "param['objective'] = 'multi:softprob'\n",
    "# scale weight of positive examples\n",
    "# param['eta'] = 0.01\n",
    "# param['max_depth'] = 6\n",
    "# param['silent'] = 1\n",
    "# param['nthread'] = 8\n",
    "param['num_class'] = len(LabelEncTarget.classes_)\n",
    "\n",
    "param['eval_metric'] = 'mlogloss'\n",
    "param['tree_method'] = 'gpu_hist'\n",
    "\n",
    "evallist = [(DTrain_X, 'train'), (DTest_X, 'Test')]\n",
    "\n",
    "param_grid = {\n",
    "#     'eta' : [0.01],\n",
    "    'max_depth': [9],\n",
    "    'subsample' : [0.7],\n",
    "#     'grow_policy' : [\"depthwise\", \"lossguide\"],\n",
    "}\n",
    "\n",
    "num_round = 1000\n",
    "\n",
    "# 参数和模型保存文件名\n",
    "params,files = extra_params(param, param_grid)\n",
    "\n",
    "# 模型保存文件路径\n",
    "model_path = \"../models/\"+str(datetime.datetime.utcnow()).replace(':','_').replace(' ', '_').replace('.', '_') + \"_\" + str(num_round)\n",
    "makedirs(model_path)\n",
    "\n",
    "# 模型文件名的含义\n",
    "modelfileformat = \"-\".join(list(param_grid))\n",
    "system(\"echo 123 > \" + model_path + \"/\" + modelfileformat)\n",
    " \n",
    "start = time.time()\n",
    "result_data = {'best_iteration' : [],\n",
    "               'best_score' : []}\n",
    "\n",
    "def eta_calc(round_index, round_count):\n",
    "    print(\"eta calc: \", round_index, round_count)\n",
    "    etas = [0.1, 0.07, 0.05, 0.01]\n",
    "    for i in range(1,1+len(etas)):\n",
    "        if round_index < round_count/len(etas)*i:\n",
    "            return etas[i-1]\n",
    "    return etas[-1]\n",
    "\n",
    "for i,a in enumerate(params):\n",
    "    bst =xgb.train(a, DTrain_X, num_round, evallist, early_stopping_rounds=None, learning_rates=eta_calc)\n",
    "    bst.save_model(model_path + \"/\" + files[i] + \".model\")\n",
    "    result_data['best_iteration'].append(bst.best_iteration)\n",
    "    result_data['best_score'].append(bst.best_score)\n",
    "\n",
    "results = pd.DataFrame(index=files, data=result_data)\n",
    "results.to_csv(model_path + \"/\" + \"result.csv\")\n",
    "\n",
    "print('GPU Training Time: %s seconds.' % (str(time.time() - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bst.attributes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datapre.extra_dates(test_data)\n",
    "test_data['DayOfWeekID'] = DayOfWeekEnc.transform(test_data['DayOfWeek'])\n",
    "test_data['PdDistrictID'] = PdDistrictEnc.transform(test_data['PdDistrict'])\n",
    "test_data = datapre.extra_address_for_block(test_data)\n",
    "test_data = datapre.extra_address_for_suffix(test_data)\n",
    "test_data['PositionTypeID'] = PositionTypeEnc.fit_transform(test_data['PositionType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"../datasets/test_preprocess.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = test_data[feature_names]\n",
    "DX_valid = xgb.DMatrix(data=X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_read = xgb.Booster()\n",
    "bst_read.load_model(\"../models/model_eta_0.01_0.01.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = np.round(bst_read.predict(DX_valid), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(884262, 39)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'Year',\n",
       "       'Month', 'Day', 'Hour', 'DayOfWeekID', 'PdDistrictID', 'HasBlock',\n",
       "       'PositionType', 'PositionTypeID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_output = pd.DataFrame(columns=LabelEncTarget.classes_, data=y_pred_prob)\n",
    "csv_output.insert(0, 'Id', test_data['Id'])\n",
    "csv_output.to_csv('./model_eta_0.01_0.01_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
